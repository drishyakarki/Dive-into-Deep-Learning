{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading and preprocessing the dataset the dataset\n",
    "\n",
    "class MTFraEng(d2l.DataModule):\n",
    "    def _download(self):\n",
    "        d2l.extract(d2l.download(d2l.DATA_URL + 'fra-eng.zip', self.root, '94646ad1522d915e7b0f9296181140edcf86a4f5'))\n",
    "        with open(self.root + '/fra-eng/fra.txt', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "        \n",
    "    def _preprocess(self, text):\n",
    "        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ') # Replace non breaking space with space\n",
    "        no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' ' # Space between words and punctuation marks\n",
    "        out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text.lower())]\n",
    "        return ''.join(out) # Join characters back into a string\n",
    "    \n",
    "    def _tokenize(self, text, max_examples = None):\n",
    "        src, tgt = [], []\n",
    "        for i, line in enumerate(text.split('\\n')): # Iterate through each line in input\n",
    "            if max_examples and i > max_examples:\n",
    "                break\n",
    "            parts = line.split('\\t') # Split lines into source and tgt\n",
    "            if len(parts) == 2: # Check if there are exactly two parts(source and target)\n",
    "                src.append([t for t in f'{parts[0]} <eos>'.split(' ') if t]) # Tokenize into source seq and append to source list\n",
    "                tgt.append([t for t in f'{parts[1]} <eos>'.split(' ') if t]) # Tokenize into target seq and append to target list\n",
    "        return src, tgt\n",
    "    \n",
    "    def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):\n",
    "        def _build_array(sentences, vocab, is_tgt=False):\n",
    "            pad_or_trim = lambda seq, t: (seq[:t] if len(seq) > t else seq + ['<pad>'] * (t-len(seq))) # Adds pad token to match the sequence length\n",
    "            sentences = [pad_or_trim(s, self.num_steps) for s in sentences]\n",
    "            if is_tgt:\n",
    "                sentences = [['<bos>'] + s for s in sentences] # If sentences are target sentenctes add bos at the begining\n",
    "            if vocab is None:\n",
    "                vocab = d2l.Vocab(sentences, min_freq=2) # If vocab is not provided, create a vocabulary\n",
    "            array = torch.tensor([vocab[s] for s in sentences]) # Convert list of sentences into tensors\n",
    "            valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "            return array, vocab, valid_len\n",
    "        src, tgt = self._tokenize(self._preprocess(raw_text), self.num_train + self.num_val)\n",
    "        src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)\n",
    "        tgt_array, tgt_vocab, tgt_valid_len = _build_array(tgt, tgt_vocab, True)\n",
    "        return ((src_array, tgt_array[:,:-1], src_valid_len, tgt_array[:, 1:]), src_vocab, tgt_vocab)\n",
    "    \n",
    "    def get_dataloader(self, train):\n",
    "        idx = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "        return self.get_tensorloader(self.arrays, train, idx)\n",
    "    \n",
    "    def build(self, src_sentences, tgt_sentences):\n",
    "        raw_text = '\\n'.join([src + '\\t' + tgt for src, tgt in zip(src_sentences, tgt_sentences)])\n",
    "        arrays, _, _ = self._build_arrays(raw_text, self.src_vocab, self.tgt_vocab)\n",
    "        return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = MTFraEng()\n",
    "raw_text = data._download()\n",
    "\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça al\n"
     ]
    }
   ],
   "source": [
    "text = data._preprocess(raw_text)\n",
    "print(text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['go', '.', '<eos>'],\n",
       "  ['hi', '.', '<eos>'],\n",
       "  ['run', '!', '<eos>'],\n",
       "  ['run', '!', '<eos>'],\n",
       "  ['who', '?', '<eos>'],\n",
       "  ['wow', '!', '<eos>']],\n",
       " [['va', '!', '<eos>'],\n",
       "  ['salut', '!', '<eos>'],\n",
       "  ['cours', '!', '<eos>'],\n",
       "  ['courez', '!', '<eos>'],\n",
       "  ['qui', '?', '<eos>'],\n",
       "  ['ça', 'alors', '!', '<eos>']])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src, tgt = data._tokenize(text)\n",
    "src[:6], tgt[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(MTFraEng)  \n",
    "def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128):\n",
    "    super(MTFraEng, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(\n",
    "        self._download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: tensor([[ 91, 191,   2,   3,   4,   4,   4,   4,   4],\n",
      "        [ 84, 127,   2,   3,   4,   4,   4,   4,   4],\n",
      "        [144, 174,   0,   3,   4,   4,   4,   4,   4]], dtype=torch.int32)\n",
      "decoder input: tensor([[  3, 211,   6,   2,   4,   5,   5,   5,   5],\n",
      "        [  3, 105,   6,   2,   4,   5,   5,   5,   5],\n",
      "        [  3,  87,   0,   4,   5,   5,   5,   5,   5]], dtype=torch.int32)\n",
      "source len excluding pad: tensor([4, 4, 4], dtype=torch.int32)\n",
      "label: tensor([[211,   6,   2,   4,   5,   5,   5,   5,   5],\n",
      "        [105,   6,   2,   4,   5,   5,   5,   5,   5],\n",
      "        [ 87,   0,   4,   5,   5,   5,   5,   5,   5]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "data = MTFraEng(batch_size=3)\n",
    "src, tgt, src_valid_len, label = next(iter(data.train_dataloader()))\n",
    "print('source:', src.type(torch.int32))\n",
    "print('decoder input:', tgt.type(torch.int32))\n",
    "print('source len excluding pad:', src_valid_len.type(torch.int32))\n",
    "print('label:', label.type(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ['hi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "target: ['<bos>', 'salut', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "src, tgt, _,  _ = data.build(['hi .'], ['salut .'])\n",
    "print('source:', data.src_vocab.to_tokens(src[0].type(torch.int32)))\n",
    "print('target:', data.tgt_vocab.to_tokens(tgt[0].type(torch.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
